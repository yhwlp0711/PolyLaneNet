[2024-04-15 14:57:23,611] [INFO] Experiment name: tusimple
[2024-04-15 14:57:23,611] [INFO] Config:
# Training settings
exps_dir: 'tusimple_bezier' # Path to the root for the experiments directory (not only the one you will run)
iter_log_interval: 50 # Log training iteration every N iterations
iter_time_window: 100 # Moving average iterations window for the printed loss metric
model_save_interval: 10 # Save model every N epochs
seed: 0 # Seed for randomness
backup: None # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 (2 points * 2))
    pretrained: true
    backbone: 'efficientnet-b0'
    pred_category: false
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 4
epochs: 100
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations: # ImgAug augmentations
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "../dataset/TUSimple/train_set/" # Dataset root

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: test
      img_size: [360, 640]
      root: "../dataset/TUSimple/test_set/"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test
[2024-04-15 14:57:23,611] [INFO] Args:
Namespace(exp_name='tusimple', cfg='./cfgs/tusimple_bezier.yaml', resume=False, validate=False, deterministic=False)
[2024-04-15 14:57:25,580] [INFO] Starting training.
[2024-04-15 14:57:25,580] [INFO] Beginning epoch 1
[2024-04-15 15:02:34,401] [INFO] Experiment name: tusimple
[2024-04-15 15:02:34,401] [INFO] Config:
# Training settings
exps_dir: 'tusimple_bezier' # Path to the root for the experiments directory (not only the one you will run)
iter_log_interval: 1 # Log training iteration every N iterations
iter_time_window: 100 # Moving average iterations window for the printed loss metric
model_save_interval: 10 # Save model every N epochs
seed: 0 # Seed for randomness
backup: None # The experiment directory will be automatically uploaded using rclone after the training ends. Leave empty if you do not want this.
model:
  name: PolyRegression
  parameters:
    num_outputs: 35 # (5 lanes) * (1 conf + 2 (upper & lower) + 4 (2 points * 2))
    pretrained: true
    backbone: 'efficientnet-b0'
    pred_category: false
loss_parameters:
  conf_weight: 1
  lower_weight: 1
  upper_weight: 1
  cls_weight: 0
  poly_weight: 300
batch_size: 4
epochs: 100
optimizer:
  name: Adam
  parameters:
    lr: 3.0e-4
lr_scheduler:
  name: CosineAnnealingLR
  parameters:
    T_max: 385

# Testing settings
test_parameters:
  conf_threshold: 0.5 # Set predictions with confidence lower than this to 0 (i.e., set as invalid for the metrics)

# Dataset settings
datasets:
  train:
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: train
      img_size: [360, 640]
      normalize: true
      aug_chance: 0.9090909090909091 # 10/11
      augmentations: # ImgAug augmentations
       - name: Affine
         parameters:
           rotate: !!python/tuple [-10, 10]
       - name: HorizontalFlip
         parameters:
           p: 0.5
       - name: CropToFixedSize
         parameters:
           width: 1152
           height: 648
      root: "../dataset/TUSimple/train_set/" # Dataset root

  test: &test
    type: LaneDataset
    parameters:
      dataset: tusimple
      split: test
      img_size: [360, 640]
      root: "../dataset/TUSimple/test_set/"
      normalize: true
      augmentations: []

  # val = test
  val:
    <<: *test
[2024-04-15 15:02:34,401] [INFO] Args:
Namespace(exp_name='tusimple', cfg='./cfgs/tusimple_bezier.yaml', resume=False, validate=False, deterministic=False)
[2024-04-15 15:02:36,466] [INFO] Starting training.
[2024-04-15 15:02:36,466] [INFO] Beginning epoch 1
[2024-04-15 15:03:40,951] [INFO] Epoch [1/100], Step [1/817], Loss: 25893.6035 (conf: 0.7048, lower: 0.1194, upper: 0.7846, poly: 25891.9941, cls_loss: 0.0000), s/iter: 50.4619, lr: 3.0e-04
[2024-04-15 15:04:28,965] [INFO] Epoch [1/100], Step [2/817], Loss: 12959.2649 (conf: 0.6814, lower: 0.0728, upper: 0.6555, poly: 23.5165, cls_loss: 0.0000), s/iter: 49.2372, lr: 3.0e-04
[2024-04-15 15:05:05,914] [INFO] Epoch [1/100], Step [3/817], Loss: 8643.4635 (conf: 0.6542, lower: 0.0302, upper: 0.5610, poly: 10.6153, cls_loss: 0.0000), s/iter: 45.1406, lr: 3.0e-04
[2024-04-15 15:05:44,157] [INFO] Epoch [1/100], Step [4/817], Loss: 6485.6132 (conf: 0.6339, lower: 0.0192, upper: 0.5097, poly: 10.8993, cls_loss: 0.0000), s/iter: 43.4158, lr: 3.0e-04
[2024-04-15 15:06:19,523] [INFO] Epoch [1/100], Step [5/817], Loss: 5451.2245 (conf: 0.6153, lower: 0.0040, upper: 0.4066, poly: 1312.6439, cls_loss: 0.0000), s/iter: 41.8056, lr: 3.0e-04
[2024-04-15 15:06:54,894] [INFO] Epoch [1/100], Step [6/817], Loss: 4544.6851 (conf: 0.5929, lower: 0.0145, upper: 0.2776, poly: 11.1035, cls_loss: 0.0000), s/iter: 40.7328, lr: 3.0e-04
[2024-04-15 15:07:33,501] [INFO] Epoch [1/100], Step [7/817], Loss: 74897.6721 (conf: 0.5872, lower: 0.0117, upper: 0.2121, poly: 497014.7812, cls_loss: 0.0000), s/iter: 40.4288, lr: 3.0e-04
[2024-04-15 15:08:06,442] [INFO] Epoch [1/100], Step [8/817], Loss: 65537.0071 (conf: 0.5569, lower: 0.0167, upper: 0.1591, poly: 11.6198, cls_loss: 0.0000), s/iter: 39.4926, lr: 3.0e-04
[2024-04-15 15:08:49,471] [INFO] Epoch [1/100], Step [9/817], Loss: 58256.7588 (conf: 0.5358, lower: 0.0448, upper: 0.0916, poly: 14.0998, cls_loss: 0.0000), s/iter: 39.8855, lr: 3.0e-04
[2024-04-15 15:09:08,972] [INFO] Epoch [1/100], Step [10/817], Loss: 52432.6603 (conf: 0.5777, lower: 0.0088, upper: 0.1055, poly: 15.0823, cls_loss: 0.0000), s/iter: 37.8469, lr: 3.0e-04
[2024-04-15 15:09:49,774] [INFO] Epoch [1/100], Step [11/817], Loss: 47675.4580 (conf: 0.5414, lower: 0.0122, upper: 0.0671, poly: 102.8143, cls_loss: 0.0000), s/iter: 38.1153, lr: 3.0e-04
[2024-04-15 15:10:21,514] [INFO] Epoch [1/100], Step [12/817], Loss: 44549.4912 (conf: 0.4803, lower: 0.0453, upper: 0.0442, poly: 10163.2871, cls_loss: 0.0000), s/iter: 37.5839, lr: 3.0e-04
[2024-04-15 15:10:49,858] [INFO] Epoch [1/100], Step [13/817], Loss: 41123.5951 (conf: 0.4768, lower: 0.0195, upper: 0.0422, poly: 12.3025, cls_loss: 0.0000), s/iter: 36.8731, lr: 3.0e-04
[2024-04-15 15:11:33,487] [INFO] Epoch [1/100], Step [14/817], Loss: 38193.4551 (conf: 0.4079, lower: 0.0191, upper: 0.0390, poly: 101.1693, cls_loss: 0.0000), s/iter: 37.3555, lr: 3.0e-04
[2024-04-15 15:12:07,450] [INFO] Epoch [1/100], Step [15/817], Loss: 35648.4093 (conf: 0.4141, lower: 0.0180, upper: 0.1096, poly: 17.2260, cls_loss: 0.0000), s/iter: 37.1293, lr: 3.0e-04
[2024-04-15 15:12:39,578] [INFO] Epoch [1/100], Step [16/817], Loss: 33421.3775 (conf: 0.4010, lower: 0.0156, upper: 0.0576, poly: 15.4265, cls_loss: 0.0000), s/iter: 36.8166, lr: 3.0e-04
[2024-04-15 15:13:14,106] [INFO] Epoch [1/100], Step [17/817], Loss: 32809.8287 (conf: 0.3659, lower: 0.0313, upper: 0.0387, poly: 23024.6133, cls_loss: 0.0000), s/iter: 36.6818, lr: 3.0e-04
[2024-04-15 15:13:57,321] [INFO] Epoch [1/100], Step [18/817], Loss: 30987.7542 (conf: 0.4054, lower: 0.0167, upper: 0.0729, poly: 11.9913, cls_loss: 0.0000), s/iter: 37.0447, lr: 3.0e-04
[2024-04-15 15:14:38,781] [INFO] Epoch [1/100], Step [19/817], Loss: 29392.7396 (conf: 0.4026, lower: 0.0201, upper: 0.1184, poly: 681.9367, cls_loss: 0.0000), s/iter: 37.2769, lr: 3.0e-04
[2024-04-15 15:15:27,808] [INFO] Epoch [1/100], Step [20/817], Loss: 28019.5642 (conf: 0.3414, lower: 0.0071, upper: 0.1105, poly: 1928.7715, cls_loss: 0.0000), s/iter: 37.8644, lr: 3.0e-04
[2024-04-15 15:16:10,826] [INFO] Epoch [1/100], Step [21/817], Loss: 26685.9068 (conf: 0.3162, lower: 0.0207, upper: 0.0480, poly: 12.3740, cls_loss: 0.0000), s/iter: 38.1097, lr: 3.0e-04
[2024-04-15 15:16:51,026] [INFO] Epoch [1/100], Step [22/817], Loss: 25473.5533 (conf: 0.2632, lower: 0.0042, upper: 0.0321, poly: 13.8301, cls_loss: 0.0000), s/iter: 38.2046, lr: 3.0e-04
[2024-04-15 15:17:26,788] [INFO] Epoch [1/100], Step [23/817], Loss: 24369.9704 (conf: 0.2889, lower: 0.0122, upper: 0.0534, poly: 90.7930, cls_loss: 0.0000), s/iter: 38.0983, lr: 3.0e-04
[2024-04-15 15:18:04,996] [INFO] Epoch [1/100], Step [24/817], Loss: 23356.2404 (conf: 0.2423, lower: 0.0077, upper: 0.0270, poly: 40.1730, cls_loss: 0.0000), s/iter: 38.1027, lr: 3.0e-04
[2024-04-15 15:18:38,340] [INFO] Epoch [1/100], Step [25/817], Loss: 22422.5322 (conf: 0.2182, lower: 0.0290, upper: 0.0280, poly: 13.2601, cls_loss: 0.0000), s/iter: 37.9123, lr: 3.0e-04
[2024-04-15 15:19:20,946] [INFO] Epoch [1/100], Step [26/817], Loss: 21560.5200 (conf: 0.2083, lower: 0.0003, upper: 0.0221, poly: 9.9844, cls_loss: 0.0000), s/iter: 38.0927, lr: 3.0e-04
[2024-04-15 15:20:07,162] [INFO] Epoch [1/100], Step [27/817], Loss: 20763.4110 (conf: 0.2553, lower: 0.0247, upper: 0.0241, poly: 38.2727, cls_loss: 0.0000), s/iter: 38.3936, lr: 3.0e-04
[2024-04-15 15:20:46,340] [INFO] Epoch [1/100], Step [28/817], Loss: 20022.3640 (conf: 0.2041, lower: 0.0074, upper: 0.0398, poly: 13.8433, cls_loss: 0.0000), s/iter: 38.4215, lr: 3.0e-04
[2024-04-15 15:21:24,948] [INFO] Epoch [1/100], Step [29/817], Loss: 19332.3859 (conf: 0.2346, lower: 0.0215, upper: 0.0238, poly: 12.7215, cls_loss: 0.0000), s/iter: 38.4278, lr: 3.0e-04
[2024-04-15 15:21:50,847] [INFO] Epoch [1/100], Step [30/817], Loss: 18688.3723 (conf: 0.3065, lower: 0.0165, upper: 0.0736, poly: 11.5790, cls_loss: 0.0000), s/iter: 38.0102, lr: 3.0e-04
[2024-04-15 15:22:31,462] [INFO] Epoch [1/100], Step [31/817], Loss: 18102.7338 (conf: 0.2614, lower: 0.0217, upper: 0.0610, poly: 533.2353, cls_loss: 0.0000), s/iter: 38.0941, lr: 3.0e-04
[2024-04-15 15:23:12,005] [INFO] Epoch [1/100], Step [32/817], Loss: 17537.8122 (conf: 0.2445, lower: 0.0005, upper: 0.0388, poly: 24.9606, cls_loss: 0.0000), s/iter: 38.1706, lr: 3.0e-04
[2024-04-15 15:23:58,798] [INFO] Epoch [1/100], Step [33/817], Loss: 17006.7800 (conf: 0.1527, lower: 0.0070, upper: 0.0184, poly: 13.5689, cls_loss: 0.0000), s/iter: 38.4318, lr: 3.0e-04
[2024-04-15 15:25:04,424] [INFO] Epoch [1/100], Step [34/817], Loss: 16511.0744 (conf: 0.4054, lower: 0.0122, upper: 0.0452, poly: 152.3272, cls_loss: 0.0000), s/iter: 39.2315, lr: 3.0e-04
[2024-04-15 15:25:39,604] [INFO] Epoch [1/100], Step [35/817], Loss: 16039.6497 (conf: 0.3397, lower: 0.0103, upper: 0.0196, poly: 10.8399, cls_loss: 0.0000), s/iter: 39.1156, lr: 3.0e-04
[2024-04-15 15:26:15,427] [INFO] Epoch [1/100], Step [36/817], Loss: 15594.4839 (conf: 0.2567, lower: 0.0056, upper: 0.0556, poly: 13.3638, cls_loss: 0.0000), s/iter: 39.0241, lr: 3.0e-04
[2024-04-15 15:26:48,701] [INFO] Epoch [1/100], Step [37/817], Loss: 15173.4320 (conf: 0.1273, lower: 0.0084, upper: 0.0192, poly: 15.4078, cls_loss: 0.0000), s/iter: 38.8686, lr: 3.0e-04
[2024-04-15 15:27:47,395] [INFO] Epoch [1/100], Step [38/817], Loss: 14776.1083 (conf: 0.1217, lower: 0.0186, upper: 0.0372, poly: 74.9553, cls_loss: 0.0000), s/iter: 39.3902, lr: 3.0e-04
[2024-04-15 15:28:22,556] [INFO] Epoch [1/100], Step [39/817], Loss: 14397.5081 (conf: 0.2842, lower: 0.0114, upper: 0.0368, poly: 10.3693, cls_loss: 0.0000), s/iter: 39.2817, lr: 3.0e-04
[2024-04-15 15:28:59,693] [INFO] Epoch [1/100], Step [40/817], Loss: 14038.0896 (conf: 0.1928, lower: 0.0201, upper: 0.0206, poly: 20.5348, cls_loss: 0.0000), s/iter: 39.2280, lr: 3.0e-04
[2024-04-15 15:29:42,317] [INFO] Epoch [1/100], Step [41/817], Loss: 13699.9727 (conf: 0.1867, lower: 0.0172, upper: 0.0765, poly: 175.0163, cls_loss: 0.0000), s/iter: 39.3108, lr: 3.0e-04
[2024-04-15 15:30:32,267] [INFO] Epoch [1/100], Step [42/817], Loss: 13374.0907 (conf: 0.1830, lower: 0.0135, upper: 0.0220, poly: 12.7102, cls_loss: 0.0000), s/iter: 39.5640, lr: 3.0e-04
[2024-04-15 15:31:28,120] [INFO] Epoch [1/100], Step [43/817], Loss: 13063.4342 (conf: 0.1034, lower: 0.0094, upper: 0.0328, poly: 15.7158, cls_loss: 0.0000), s/iter: 39.9428, lr: 3.0e-04
[2024-04-15 15:32:13,371] [INFO] Epoch [1/100], Step [44/817], Loss: 12766.8706 (conf: 0.1771, lower: 0.0114, upper: 0.0564, poly: 14.3895, cls_loss: 0.0000), s/iter: 40.0633, lr: 3.0e-04
[2024-04-15 15:32:47,529] [INFO] Epoch [1/100], Step [45/817], Loss: 12486.4481 (conf: 0.2667, lower: 0.0301, upper: 0.0683, poly: 147.4916, cls_loss: 0.0000), s/iter: 39.9321, lr: 3.0e-04
[2024-04-15 15:33:37,120] [INFO] Epoch [1/100], Step [46/817], Loss: 12215.3003 (conf: 0.0882, lower: 0.0107, upper: 0.0099, poly: 13.5403, cls_loss: 0.0000), s/iter: 40.1420, lr: 3.0e-04
